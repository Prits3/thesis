{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d537615-82fb-4457-be88-8489b7ea2866",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c76f74-e331-47ee-ac5a-6b0dfe0185a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /opt/anaconda3/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: googletrans in /opt/anaconda3/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: httpx==0.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from googletrans) (0.13.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
      "Requirement already satisfied: hstspreload in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (2024.9.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
      "Requirement already satisfied: deep_translator in /opt/anaconda3/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from deep_translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from deep_translator) (2.32.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2024.8.30)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fuzzy-wuzzy (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fuzzy-wuzzy\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: rapidfuzz in /opt/anaconda3/lib/python3.12/site-packages (3.9.7)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.12/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n",
    "!pip install googletrans\n",
    "!pip install deep_translator\n",
    "!pip install fuzzy-wuzzy\n",
    "!pip install rapidfuzz\n",
    "!pip install spacy\n",
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab895b1d-1337-4a99-8fa8-d32ca76bece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pritika_timsina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/anaconda3/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from deep_translator import GoogleTranslator\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from flask import Flask, request, render_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34680f22-199a-4ff2-9418-57818ce68be1",
   "metadata": {},
   "source": [
    "### Loading the JSON File that was created with the client information in python to preprocess and normalize it so that the system can understand it provide results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82fe7d6-27c0-41aa-8900-482fc3313ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Building digital ecosystem', 'subtitle': 'Building & Living for a leading banking group', 'context': 'In view of increasing competition from FinTechs and PropTechs, traditional banks must find ways to maintain the customer interface and develop new revenue potential beyond classic financial services.', 'sections': [{'title': 'Strategic target image', 'details': ['Conception of a strategic target image for the holistic occupation of different people.', \"Customer journeys in the 'Building & Living' area and creation of a comprehensive market analysis.\", 'Definition of a balanced portfolio of opportunity areas and initiatives.']}, {'title': 'Customer offer & testing', 'details': [\"Analysis and prioritization of different 'living worlds'.\", 'Creation and prioritization of a long list of over 130 service ideas for the ecosystem offering.', 'Rapid prototyping of four services, testing for end customers as well as potential sponsors and partners internally and externally.']}, {'title': 'Implementation roadmap', 'details': [\"Derived from the strategic target image and the customer's existing assets, an implementation roadmap for 12 months and a high-level business case were defined.\", 'In addition to technical and organizational requirements, technical specifications were also defined for part of the offer.']}, {'title': 'Opinion formation process', 'details': ['Regular coordination in direction and decision-making committees as well as continuous collaboration with the core and project team of 15 participants.', 'Preparation and moderation of workshops, implementation of jour fixes, management of small groups.']}]}\n",
      "{'title': 'Development of an ecosystem strategy', 'context': 'Traditional banks are coming under increasing pressure in competition with tech players for customer access and interface. In response, we developed an ecosystem strategy as well as new business model and service approaches for a leading German banking group in order to systematically strengthen the customer interface.', 'sections': [{'title': 'Strategic target image', 'details': ['At the core of the ecosystem strategy, we have four opportunity spaces for dedicated innovation activities identified.', 'Defined the requirements for a future product and service portfolio.', 'Developed a strategic framework for the allocation of resources within the opportunity areas.']}, {'title': 'Customer survey', 'details': ['Conducted a representative, quantitative customer survey (> 1000 private customers, > 250 corporate customers).', 'Validated hypotheses for private and corporate customer business.', 'Derived strategic fields of action for new value creation models and value propositions.']}, {'title': 'Conception sprints', 'details': ['Developed product concepts in three innovation fields - new contact points, new services, new business models.', 'Result: > 70 PK and FK concepts on longlist and 18 prioritized.', 'Detailed concepts for an implementation roadmap.']}, {'title': 'Prototyping & validation', 'details': ['Four particularly successful promising product concepts were transferred to a separate governance structure at predefined project times.', 'These were prototyped in a sprint logic, validated and, if the result was positive, immediately implemented.']}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('/Users/pritika_timsina/Desktop/tlgg.json', 'r') as t:\n",
    "    data = json.load(t)\n",
    "\n",
    "# Display the first one or two lines (or entries) of the data\n",
    "for entry in data.get('slides', [])[:2]:  # Adjust the slice to show more or fewer entries\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9b208-e3f7-406c-8f30-cc9de7ecd2cd",
   "metadata": {},
   "source": [
    "#### Creating a query to check whether the JSON file is working or not, and if the machine can understand it. To achieve this we first convert each query to lowercase. Then we loop through the entire text in the JSON data to normalize each and every section in the file and make it lowercase. Next we have each and every section to if query is present in any section title, context or deatils and it is present there the function stops looking for it. \n",
    "\n",
    "#### Next we move to test if the function works properly or not, for this a query box is created, where the user can ask particular questions and since the data is limited to train the machine well at this step it can't preprocess every question smoothly, hence we have to set criterias to check result by assiting the function to move through each line and when relevant information is found it is displayed to the user or else a text is shown which asks the user to retry typing the question.\n",
    "\n",
    "\n",
    "#### This part of the code will scan through the entire file and give the slide will all the inofrmation where Customer solution is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d37cf3-c90c-4034-96d0-9d5965fc0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type your question:  digital \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: building digital ecosystem\n",
      "Context: in view of increasing competition from fintechs and proptechs, traditional banks must find ways to maintain the customer interface and develop new revenue potential beyond classic financial services.\n",
      "\n",
      "Title: platform strategy for a decentralized organization\n",
      "Context: digital brokerage platforms create transparency in financial products and increasingly occupy the customer interface. a decentralized organization commissioned tlgg consulting to formulate strategic recommendations for sales.\n",
      "\n",
      "Title: optimization of the transformation strategy of a large german insurance group\n",
      "Context: like many large, traditional companies, our customer faced the challenge of becoming fit for digitalization. despite good framework conditions - such as a cdo with its own unit and 'transformation managers' - there was a lack of a unified vision and a clear target image.\n",
      "\n",
      "Title: digital solutions for a young target group\n",
      "Context: for many people under 30, 'building savings' is a thing of the past. cheap interest rates and fintechs have left old providers behind. we aimed to make the product future-proof and explore new business models.\n",
      "\n",
      "Title: growth strategy for a leading medium-sized bank\n",
      "Context: interest rate pressure and new customer requirements are putting today's corporate banking under pressure. we aimed to develop a 'beyond banking' vision for growth outside the classic core business.\n",
      "\n",
      "Title: validating and building a d2c brand for hearing aids\n",
      "Context: a leading hearing aid manufacturer sought to enter the market with an innovative product. we focused on addressing new customer segments via digital sales channels.\n",
      "\n",
      "Title: digital campaign for addressing young people for the nursing service\n",
      "Context: the federal ministry for family, women, senior citizens and youth aimed to inspire careers in nursing and attract potential trainees, students, and pupils.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/pritika_timsina/Desktop/tlgg.json', 'r') as t:\n",
    "    file = json.load(t)\n",
    "\n",
    "def normalize_data():\n",
    "    for entry in file.get('slides', []):\n",
    "        entry['title'] = entry.get('title', '').lower()\n",
    "        entry['context'] = entry.get('context', '').lower()\n",
    "        for section in entry.get('sections', []):\n",
    "            section['title'] = section.get('title', '').lower()\n",
    "            section['details'] = [detail.lower() for detail in section.get('details', [])]\n",
    "\n",
    "def search_data(query):\n",
    "    query = query.lower() \n",
    "    res = []\n",
    "    \n",
    "    for entry in file.get('slides', []):\n",
    "        if query in entry['title'] or query in entry['context']:\n",
    "            res.append(entry)\n",
    "            continue \n",
    "\n",
    "        for section in entry.get('sections', []):\n",
    "            if query in section['title'] or any(query in detail for detail in section['details']):\n",
    "                res.append(entry)\n",
    "                break  \n",
    "    return res\n",
    "\n",
    "def format_results(results):\n",
    "    formatted = []\n",
    "    for result in results:\n",
    "        output = f\"Title: {result.get('title', 'N/A')}\\n\"\n",
    "        output += f\"Context: {result.get('context', 'N/A')}\\n\"\n",
    "        formatted.append(output)\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_data()  \n",
    "    query = input(\"Please type your question: \")\n",
    "    res = search_data(query)\n",
    "    if res:\n",
    "        print(format_results(res))\n",
    "    else:\n",
    "        print(\"No relevant information found. Try again with a different question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78c31d-6b6c-4a32-ac04-c42e105755ad",
   "metadata": {},
   "source": [
    "##### As the AI system is almost built at the foundation level, and although we changed just the data to German we have to be prepared in all cases we cant keep converting data into German and do the whole process again hence the second option would be integrated translation function with the search function so that whenever the user has a new query that is in a different language than the content translation is provided. \n",
    "\n",
    "##### The code below basically translates and preprocesses the user's queries and the contents in the JSON file The code translates and matches to generate results. The code's main function is to scan through titles, and each content in all the sections of the slide using the Fuzzy matching technique, after finding the relevant match in the file it returns the output to the user. The code also supports cross-language queries that can translate both data and the query itself providing users with what they want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3703708a-5ca6-474f-a2ef-1cd2dd42a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type your question:  digital\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Query: digital\n",
      "Preprocessed Query: ['digital']\n",
      "Slide Title: building digital ecosystem\n",
      "Context: angesichts der zunehmenden konkurrenz durch fintechs und proptechs müssen traditionelle banken wege finden, die kundenschnittstelle aufrechtzuerhalten und neue umsatzpotenziale jenseits klassischer finanzdienstleistungen zu erschließen.\n",
      "Sections:\n",
      "  Section Title: strategisches zielbild\n",
      "    - konzeption eines strategischen zielbildes zur ganzheitlichen beschäftigung unterschiedlicher menschen.\n",
      "    - customer journeys im bereich „bauen & wohnen“ und erstellung einer umfassenden marktanalyse.\n",
      "    - definition eines ausgewogenen portfolios aus chancebereichen und initiativen.\n",
      "--------\n",
      "  Section Title: kundenangebot & tests\n",
      "    - analyse und priorisierung unterschiedlicher wohnwelten.\n",
      "    - erstellung und priorisierung einer langen liste mit über 130 serviceideen für das ökosystemangebot.\n",
      "    - rapid prototyping von vier diensten, tests für endkunden sowie potenzielle sponsoren und partner intern und extern.\n",
      "--------\n",
      "  Section Title: implementierungs-roadmap\n",
      "    - abgeleitet aus dem strategischen zielbild und den vorhandenen assets des kunden wurden eine implementierungs-roadmap für 12 monate und ein high-level business case definiert.\n",
      "    - neben den technischen und organisatorischen anforderungen wurden für einen teil des angebots auch technische spezifikationen definiert.\n",
      "--------\n",
      "  Section Title: meinungsbildungsprozess\n",
      "    - regelmäßige abstimmungen in leitungs- und entscheidungsgremien sowie kontinuierliche zusammenarbeit mit dem 15-köpfigen kern- und projektteam.\n",
      "    - vorbereitung und moderation von workshops, durchführung von jour fixes, leitung von kleingruppen.\n",
      "--------\n",
      "Slide Title: platform strategy for a decentralized organization\n",
      "Context: digitale brokerage-plattformen schaffen transparenz bei finanzprodukten und besetzen zunehmend die kundenschnittstelle. eine dezentrale organisation beauftragte tlgg consulting, strategische empfehlungen für den vertrieb zu erarbeiten.\n",
      "Sections:\n",
      "  Section Title: entscheidungsvorlage und business case\n",
      "    - erstellung einer entscheidungsvorlage und eines strategiepapiers mit strategischen empfehlungen, drei business cases und anforderungen für die weitere umsetzung.\n",
      "--------\n",
      "  Section Title: prototyping von lösungsansätzen\n",
      "    - rapid prototyping von zwei klick-dummys und zwei produkt-mockups als konkrete lösungen.\n",
      "    - konzeption, steuerung und auswertung eines quantitativen und qualitativen tests zur validierung mit internen und externen zielgruppen.\n",
      "--------\n",
      "  Section Title: koordination mit rund 100 stakeholdern\n",
      "    - regelmäßige abstimmungen in leitungs- und entscheidungsgremien mit einem 30-köpfigen kern- und projektteam.\n",
      "    - vorbereitung und moderation von workshops, durchführung von jour fixes und leitung von kleingruppen.\n",
      "--------\n",
      "Slide Title: optimization of the transformation strategy of a large german insurance group\n",
      "Context: wie viele große, traditionelle unternehmen stand auch unser kunde vor der herausforderung, fit für die digitalisierung zu werden. trotz guter rahmenbedingungen – wie einem cdo mit eigener einheit und ‚transformationsmanagern‘ – fehlte es an einer einheitlichen vision und einem klaren zielbild.\n",
      "Sections:\n",
      "  Section Title: digitale strategie\n",
      "    - unterstützt durch eine umfassende outside-in-perspektive resultiert daraus eine vom vorstand genehmigte digitale strategie, einschließlich einer digitalen roadmap.\n",
      "--------\n",
      "  Section Title: maßgeschneiderte organisationsform\n",
      "    - iterativ arbeitete ich mit dem kernteam an der entwicklung und einführung einer maßgeschneiderten organisationsform für die digitaleinheit.\n",
      "--------\n",
      "  Section Title: kollaborativer roadmap-prozess\n",
      "    - entwickelte einen prozess zur koordination aller digitalen initiativen und projekte, der alle perspektiven in die weitere entwicklung einbezieht.\n",
      "--------\n",
      "  Section Title: eine strategie für den cdo\n",
      "    - entwickelte in enger abstimmung mit dem chief digital officer eine strategie, um die digitale einheit stärker in die gruppe zu integrieren.\n",
      "--------\n",
      "Slide Title: digital solutions for a young target group\n",
      "Context: for many people under 30, 'building savings' is a thing of the past. cheap interest rates and fintechs have left old providers behind. we aimed to make the product future-proof and explore new business models.\n",
      "Sections:\n",
      "  Section Title: exploration opportunity space\n",
      "    - exploratory interviews revealed new opportunities with a changed product and approach.\n",
      "    - market and competition analyses identified gaps in the market for new customer segments.\n",
      "--------\n",
      "  Section Title: ideation & prioritization\n",
      "    - developed and prioritized ideas in workshops, assessing feasibility, investments, and existing assets.\n",
      "--------\n",
      "  Section Title: concept & decision template\n",
      "    - refined prioritized ideas into concepts.\n",
      "    - collected facts in a decision template, including assessment of implementation.\n",
      "--------\n",
      "  Section Title: results\n",
      "    - 15 ideas including a blockchain-based platform for real estate history, crowdfunding for real estate purchases, and an advisor platform.\n",
      "    - provided methodology and know-how for an agile, independent team.\n",
      "--------\n",
      "Slide Title: growth strategy for a leading medium-sized bank\n",
      "Context: interest rate pressure and new customer requirements are putting today's corporate banking under pressure. we aimed to develop a 'beyond banking' vision for growth outside the classic core business.\n",
      "Sections:\n",
      "  Section Title: customer understanding build-up\n",
      "    - analyzed and prioritized 14 business challenges in relevant customer segments based on outside-in perspective.\n",
      "--------\n",
      "  Section Title: derive opportunity spaces\n",
      "    - created a long list of five opportunity areas and prioritized three in a joint strategy workshop.\n",
      "--------\n",
      "  Section Title: validate and pilot feasibility\n",
      "    - validated priority topics based on internal and external expert interviews, focusing on embedded finance and digital cfo ecosystems.\n",
      "--------\n",
      "  Section Title: design roadmap\n",
      "    - developed an implementation concept, networked with strategic partners, and created roadmaps for pilot projects.\n",
      "--------\n",
      "Slide Title: validating and building a d2c brand for hearing aids\n",
      "Context: a leading hearing aid manufacturer sought to enter the market with an innovative product. we focused on addressing new customer segments via digital sales channels.\n",
      "Sections:\n",
      "  Section Title: go-to-market\n",
      "    - conducted smoke tests with landing pages, ads, and non-functional online shops to validate go-to-market hypotheses.\n",
      "--------\n",
      "  Section Title: digital ecosystem\n",
      "    - designed user flows, services, and requirements for the e-commerce ecosystem, selecting store systems and integrations.\n",
      "--------\n",
      "  Section Title: operations\n",
      "    - selected and onboarded customer service and fulfillment partners, defining core processes for a seamless user experience.\n",
      "--------\n",
      "  Section Title: results\n",
      "    - validated go-to-market strategy for two products, designed user flows and services, and selected shop systems and partners for three main markets.\n",
      "--------\n",
      "Slide Title: digital campaign for addressing young people for the nursing service\n",
      "Context: the federal ministry for family, women, senior citizens and youth aimed to inspire careers in nursing and attract potential trainees, students, and pupils.\n",
      "Sections:\n",
      "  Section Title: goal-oriented implementation\n",
      "    - defined and characterized three target groups and addressed them with the slogan 'care can do something.'\n",
      "    - used a diverse cast and distinctive design, including a specially developed logo.\n",
      "    - implemented a 360° campaign across online and offline channels.\n",
      "--------\n",
      "  Section Title: results\n",
      "    - reached over 129 million users online (social media) and over 93 million contacts (print & digital).\n",
      "    - achieved an average view-through rate of campaign spots on youtube over 50%.\n",
      "    - further measures will be designed and implemented up to and including 2025, including additional productions, content formats, and a care award.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as t:\n",
    "        return json.load(t)\n",
    "\n",
    "# Translate text\n",
    "def translate_text(text, src_lang='en', dest_lang='en'):\n",
    "    if src_lang != dest_lang:\n",
    "        return GoogleTranslator(source=src_lang, target=dest_lang).translate(text)\n",
    "    return text\n",
    "\n",
    "# Preprocess text (placeholder for your preprocessing logic)\n",
    "def preprocess_text(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Fuzzy matching function (placeholder for your fuzzy matching logic)\n",
    "def fuzzy_match(word, text):\n",
    "    return word in text\n",
    "\n",
    "# Normalizing the JSON data\n",
    "def normalize_data(data):\n",
    "    for entry in data.get('slides', []):\n",
    "        entry['title'] = entry.get('title', '').lower()\n",
    "        entry['context'] = entry.get('context', '').lower()\n",
    "        for section in entry.get('sections', []):\n",
    "            section['title'] = section.get('title', '').lower()\n",
    "            section['details'] = [detail.lower() for detail in section.get('details', [])]\n",
    "\n",
    "def search_data(query, data, src_lang='en', dest_lang='de'):\n",
    "    \"\"\"Search data with translation and preprocessing.\"\"\"\n",
    "    translated_query = translate_text(query, src_lang, dest_lang)\n",
    "    preprocessed_query = preprocess_text(translated_query)\n",
    "\n",
    "    res = []\n",
    "    print(f\"Translated Query: {translated_query}\")\n",
    "    print(f\"Preprocessed Query: {preprocessed_query}\")\n",
    "\n",
    "    for slide in data.get('slides', []):\n",
    "        slide_title = translate_text(slide.get('title', ''), src_lang, dest_lang)\n",
    "        slide_context = translate_text(slide.get('context', ''), src_lang, dest_lang)\n",
    "        title = preprocess_text(slide_title)\n",
    "        context = preprocess_text(slide_context)\n",
    "\n",
    "        if any(fuzzy_match(word, ' '.join(title)) for word in preprocessed_query) or \\\n",
    "           any(fuzzy_match(word, ' '.join(context)) for word in preprocessed_query):\n",
    "            res.append(slide)\n",
    "            continue\n",
    "\n",
    "        for section in slide.get('sections', []):\n",
    "            section_title = translate_text(section.get('title', ''), src_lang, dest_lang)\n",
    "            section_details = [translate_text(detail, src_lang, dest_lang) for detail in section.get('details', [])]\n",
    "            section_title_processed = preprocess_text(section_title)\n",
    "            section_details_processed = [preprocess_text(detail) for detail in section_details]\n",
    "\n",
    "            if any(fuzzy_match(word, ' '.join(section_title_processed)) for word in preprocessed_query) or \\\n",
    "               any(fuzzy_match(word, ' '.join(' '.join(detail) for detail in section_details_processed)) for word in preprocessed_query):\n",
    "                res.append(slide)\n",
    "                break\n",
    "\n",
    "    return res\n",
    "\n",
    "def print_results(results):\n",
    "    \"\"\"Print the search results.\"\"\"\n",
    "    if results:\n",
    "        for result in results:\n",
    "            print(f\"Slide Title: {result.get('title', 'N/A')}\")\n",
    "            print(f\"Context: {result.get('context', 'N/A')}\")\n",
    "            print(\"Sections:\")\n",
    "            for section in result.get('sections', []):\n",
    "                print(f\"  Section Title: {section.get('title', 'N/A')}\")\n",
    "                for detail in section.get('details', []):\n",
    "                    print(f\"    - {detail}\")\n",
    "                print(\"--------\")\n",
    "    else:\n",
    "        print(\"No relevant information found. Try again with a different question.\")\n",
    "\n",
    "# Main function to test the search\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/Users/pritika_timsina/Desktop/translated_tlgg.json'\n",
    "    data = load_data(file_path)\n",
    "    normalize_data(data)  # Normalize the JSON data first\n",
    "    query = input(\"Please type your question: \")\n",
    "    results = search_data(query, data, 'en', 'de')\n",
    "    print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db108e-d44e-4118-ab49-8bfdb60ed261",
   "metadata": {},
   "source": [
    "## Testing the system \n",
    "\n",
    "#### to test the accuracy of the system the first step is to create a dataset from some of the queries that might be asked from the users. After that we create a function for accuracy test and add in a formula to check the of correct answers divided by the total which gives the results for accuracy.\n",
    "#### Next we do the same for precision but just change the formula, precision test usually also deal with true positives and false positives as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88800d-5a29-4ff6-821c-5cb99a8b6f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Query: Innovative digitale Lösungen für das moderne Publikum\n",
      "Preprocessed Query: ['innovative', 'digitale', 'lösungen', 'für', 'das', 'moderne', 'publikum']\n",
      "Translated Query: Neue Mobilitätslösungen\n",
      "Preprocessed Query: ['neue', 'mobilitätslösungen']\n",
      "Translated Query: Nicht verwandte Abfrage\n",
      "Preprocessed Query: ['nicht', 'verwandte', 'abfrage']\n",
      "Accuracy: 66.67%\n",
      "Translated Query: Innovative digitale Lösungen für das moderne Publikum\n",
      "Preprocessed Query: ['innovative', 'digitale', 'lösungen', 'für', 'das', 'moderne', 'publikum']\n",
      "Translated Query: Neue Mobilitätslösungen\n",
      "Preprocessed Query: ['neue', 'mobilitätslösungen']\n",
      "Translated Query: Nicht verwandte Abfrage\n",
      "Preprocessed Query: ['nicht', 'verwandte', 'abfrage']\n"
     ]
    }
   ],
   "source": [
    "# using data from the file to create queries.\n",
    "real_queries = [\n",
    "    (\"Innovative digital solutions for modern audiences\", True),  # Should return relevant result\n",
    "    (\"New mobility solutions\", True),  # Should return relevant result\n",
    "    (\"Unrelated query\", False)  # This should generate no results\n",
    "]\n",
    "\n",
    "def accuracy_test_with_data(real_queries, data):\n",
    "    correct = 0\n",
    "    total = len(real_queries)\n",
    "    \n",
    "    for query, expected in real_queries:\n",
    "        results = search_data(query, data)\n",
    "        if (len(results) > 0) == expected:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Running accuracy test \n",
    "accuracy = accuracy_test_with_data(real_queries, data)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "def precision_test_with_data(real_queries, data):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "\n",
    "    for query, expected in real_queries:\n",
    "        results = search_data(query, data)\n",
    "        if len(results) > 0:  \n",
    "            if expected:  \n",
    "                true_positive += 1\n",
    "            else:  \n",
    "                false_positive += 1\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    return precision\n",
    "\n",
    "# Running precision test\n",
    "precision = precision_test_with_data(real_queries, data)\n",
    "print(f\"Precision: {precision * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58ae24-221d-4c2e-a5d6-721829d5a3ee",
   "metadata": {},
   "source": [
    "#### Having a good UI/UX is super important in any digital solution and hence the code above makes it easier for the users to type in the queries mostly focusing on the CLI but along with it GUI is super essential. Hence, the code below is GUI code to just make things easier once it's deployed it is just a suggestion that can tried out when this system is deployed. \n",
    "\n",
    "##### The code uses something called Flask which is a basic web application that assists users through queries permitting them to ask questions based on the information in the file. Once it receives the query the function scans through the JSON file. The search funtion preprocesses the user query and converts it to lowercase and scans through all the title fields of in the JSON file to find relevant data that matches the query. The 'GET' and 'POST' is handled well in the requests. When the user submits a search query from POST the Flask app loads and scans the data for relevant matches and then generates results in a separate result page which is in html format or it is .html doc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
